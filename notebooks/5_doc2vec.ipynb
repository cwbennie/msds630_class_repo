{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d38ade95-caba-4007-a6ad-33901f984fbd",
   "metadata": {},
   "source": [
    "# Doc2vec from scratch in PyTorch\n",
    "We will be implementing this paper https://arxiv.org/abs/1405.4053"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "732927ef-c76d-4385-8169-f4efe698819e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch \n",
    "import torch.autograd as autograd \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a991a97-7638-4bfa-8379-e12cc0688881",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Subjectivity Dataset\n",
    "The subjectivity dataset has 5000 subjective and 5000 objective processed sentences. To get the data:\n",
    "```\n",
    "wget http://www.cs.cornell.edu/people/pabo/movie-review-data/rotten_imdb.tar.gz\n",
    "```\n",
    "Download this data and save it in dir data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "207466ae-cd62-4278-8e7c-99c0f6a66a1c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plot.tok.gt9.5000   quote.tok.gt9.5000  subjdata.README.1.0\n"
     ]
    }
   ],
   "source": [
    "!ls data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6a306b6-0741-40bd-9046-969b1487e4c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_file(path):\n",
    "    \"\"\" Read file returns a list of lines.\n",
    "    \"\"\"\n",
    "    with open(path, encoding = \"ISO-8859-1\") as f:\n",
    "        content = f.readlines()\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d7a93579-40ca-4efd-8bc2-84c72f8432fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "obj_content = read_file(\"data/plot.tok.gt9.5000\")\n",
    "sub_content = read_file(\"data/quote.tok.gt9.5000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "01d4054a-fdba-45b1-bfc5-bf2d05e98551",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 5000)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(obj_content), len(sub_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5702b5a-7179-45a9-97e0-ab13f7c71cfc",
   "metadata": {},
   "source": [
    "### Compute vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f72ce1ef-fed0-40cb-b904-cf1d71cab57f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "def get_vocab(content):\n",
    "    \"\"\"Computes Dict of counts of words.\n",
    "    \n",
    "    Computes the number of times a word is on a document.\n",
    "    \"\"\"\n",
    "    vocab = defaultdict(float)\n",
    "    for line in content:\n",
    "        words = set(line.split())\n",
    "        for word in words:\n",
    "            vocab[word] += 1\n",
    "    return vocab    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b826e9dd-f26d-4bbf-97eb-0c601b1cd769",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sub_content = np.array([line.strip().lower() for line in sub_content])\n",
    "obj_content = np.array([line.strip().lower() for line in obj_content])\n",
    "content = np.append(sub_content, obj_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bbb69546-f3dc-4745-97ed-d1d6642f398b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'smart and alert , thirteen conversations about one thing is a small gem .'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d9e78b96-18a4-4da3-a7aa-fdb0ca231f8e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23908"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_count = get_vocab(content)\n",
    "len(word_count.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c7b78655-48c2-4098-b386-f9c6bb140bb6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4836"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's delete words that are very infrequent\n",
    "for word in list(word_count):\n",
    "    if word_count[word] < 5:\n",
    "        del word_count[word]\n",
    "len(word_count.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d1749628-559b-4a36-937c-0c94ef78dfee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vocab2index = {\"<PAD>\":0, \"UNK\":1} # init with padding and unknown\n",
    "words = [\"<PAD>\", \"UNK\"]\n",
    "for word in word_count:\n",
    "    vocab2index[word] = len(words)\n",
    "    words.append(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09750f25-ba77-43a5-a729-dc8bcaa98f03",
   "metadata": {},
   "source": [
    "## Sentence enconding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a9514cae-b640-4aed-9903-e55c48c53ed3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def encode_sentence(s):\n",
    "    enc = np.array([vocab2index.get(w, vocab2index[\"UNK\"]) for w in s.split()])\n",
    "    return enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "173180ee-5612-415d-9b0f-0f3597cc9963",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([13,  2, 14, 11,  1,  9,  3,  7,  6, 12,  8,  5,  4, 10])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode_sentence(content[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b71b269b-0526-41d3-b906-3d5f8321f8d8",
   "metadata": {},
   "source": [
    "### Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8f289a5e-bea1-4951-b06d-81c1ce38db73",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([13,  2, 14, 11,  1,  9,  3,  7,  6, 12,  8,  5,  4, 10])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = encode_sentence(content[0])\n",
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e898e850-4ed4-42f7-abea-6985ce209dc1",
   "metadata": {},
   "source": [
    "We need to be able to sample $k$ words to predict the $k+1$th word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "908122e0-1cee-46c2-830b-560e64cd8cdb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sample(text, k=3):\n",
    "    \"\"\" Given a list of ids sample k consecutive words\n",
    "    to predict the k+1th\n",
    "    \"\"\"\n",
    "    n = len(text)\n",
    "    s = np.random.randint(n-k, size=1)[0]\n",
    "    return text[s:s+k], text[s+k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d063610a-10ec-42c7-bb70-bd91cde65c17",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([ 7,  6, 12]), 8)\n",
      "(array([ 6, 12,  8]), 5)\n",
      "(array([14, 11,  1]), 9)\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    print(sample(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "098e2045-84f4-453a-a8cc-17ade90983bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Wor2VecDataset(Dataset):\n",
    "    def __init__(self, content, k=3):\n",
    "        self.content = content\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.content)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = self.content[idx]\n",
    "        doc_id = idx\n",
    "        context, next_word = sample(text)\n",
    "        return doc_id, context, next_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2ffabf37-68df-4019-bb9a-d3e8b63bfbe5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([13,  2, 14, 11,  1,  9,  3,  7,  6, 12,  8,  5,  4, 10])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_text = [encode_sentence(text) for text in content]\n",
    "encoded_text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c89bded9-1ff6-48b1-b18e-addb7e2b90a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_ds = Wor2VecDataset(encoded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e260653e-c8e5-4b3e-8a68-65fe3a8870da",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, array([12,  8,  5]), 4)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b9bcb691-a36d-44df-8446-d8a8371f9fe5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dl =  DataLoader(train_ds, batch_size=2, shuffle=True)\n",
    "doc_id, context, next_word = next(iter(train_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "722d1930-b741-4e2c-b204-f27685f1db0b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([9363, 7432]),\n",
       " tensor([[2332, 1404,   28],\n",
       "         [1314, 4546,  109]]),\n",
       " tensor([  12, 2622]))"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_id, context, next_word "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db47c2bb-4fcd-41c1-a066-b2549c85d336",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "eaa45c4d-2528-4ee0-8854-955beed46bb1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4838, 10000)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab2index), len(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "1f7dcb4b-9d93-4355-b651-06491aee7980",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vocab_size = len(vocab2index)\n",
    "num_docs =  len(train_ds)\n",
    "emb_size = 100\n",
    "\n",
    "word_emb = nn.Embedding(vocab_size, emb_size)\n",
    "doc_emb = nn.Embedding(num_docs, emb_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c572302f-7e9d-4dc9-b1b7-aa3ea0cec92f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 100])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_id = doc_emb(doc_id)\n",
    "doc_id.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "129a849c-4f44-47b5-870b-34d547ff062b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 100])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_emb = word_emb(context)\n",
    "context_emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "97c56546-24cc-4e29-9a3a-1fbed1b2494d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 300])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_emb_flat = context_emb.flatten(1)\n",
    "context_emb_flat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "06f14af3-06ed-47c8-9d2f-9afb14bc61ba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 400])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.cat((doc_id, context_emb_flat), dim=1)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "1de92ce8-d420-4f37-92d6-e194b873f55e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "linear = nn.Linear(4*emb_size, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "6a3f0fc3-455d-4229-bfb3-2ee303b2834d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4838])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "2d10a645-e720-49a3-ae7c-c68b7f00e5d6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(8.8092, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.cross_entropy(linear(x), next_word )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "6a4ad456-9983-49a4-b0f5-fca75bf4e97d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Doc2Vec(nn.Module):\n",
    "    def __init__(self, vocab_size, num_docs, emb_size=100):\n",
    "        super(Doc2Vec, self).__init__()\n",
    "        ### Your code here\n",
    "        \n",
    "    def forward(self, x_doc, x_words):\n",
    "        ## Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "230ee85b-a5f6-4c52-8b9d-5a43f4e54a93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = Doc2Vec(vocab_size, num_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "70f49b21-27f7-41b6-8542-c07d4b27fdd3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_epocs(model, train_dl, optimizer, epochs=10000):\n",
    "    #Your CODE HERE\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "        if i%1000:\n",
    "            print(\"train_loss %.3f\" % (train_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "daf191ea-2cad-4d27-ac96-a9fdca7e810b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = Doc2Vec(vocab_size, num_docs)\n",
    "train_dl =  DataLoader(train_ds, batch_size=1000, shuffle=True)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "bf3f4132-6e99-442b-922a-b210ca1261c3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1000]), torch.Size([1000, 3]), torch.Size([1000]))"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_id, context, next_word = next(iter(train_dl))\n",
    "doc_id.shape, context.shape, next_word.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be74ea76-94fa-469c-93c2-ad0365245c61",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#train_epocs(model, train_dl, optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ffa64a5-2aca-4438-b4e6-cb0d467929a8",
   "metadata": {},
   "source": [
    "### Lab:\n",
    "1. Finish writting the model and the training loop.\n",
    "2. Can you use the doc embeddings learned by the model to predict the orriginal label (0,)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
